
# Lecture-2

| S.N | Resource | Links |
| ---- | ---- | ---- |
| 1. | RL Course by David silver- Lecture 2 | [Video Link](https://www.youtube.com/watch?v=lfHX2hHRMVQ&list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ&index=2) |
| 2. | Course slides -  Lecture 2 | [Slides link](https://www.davidsilver.uk/wp-content/uploads/2020/03/MDP.pdf) |
> [!quote] **Outline** 
> - Markov Processes
> - Markov Reward process
> - Markov Decision process(MDP)
> - Extension to MDP

---


## Markov Decision Processes
### Markov Processes
#### Introduction to MDPs
- MDP formally describe an environment of Reinforcement learning.
- In this case the environment is fully observable. The current state completely characterizes the process.
- Almost all RL problems can be formalized as MDPs fir example: 
	- optimal control which deals with continuous MDPs. 
	- Partially observable problems can be converted into MDPs
	- Bandits are MDPs with one state.(will be discussed later). This is the case where MDP with only one state.


---
